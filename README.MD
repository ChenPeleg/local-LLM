# Local LLM for Private Use

A guide for setting up and using LM Studio with VS Code for local, private AI-assisted development.

## Documentation

- **[Setup Guide](01-setup-env.md)** - Complete installation and configuration checklist
- **[Usage Guide](02-using-lm-studio-with-vscode.md)** - How to use LM Studio server with VS Code
- **[CLI Tools Reference](plan/02-create-cli-tools.md)** - LM Studio command-line interface commands

## Quick Start

1. Follow the [Setup Guide](01-setup-env.md) to install LM Studio and download a model
2. Start the LM Studio server
3. Use the [Usage Guide](02-using-lm-studio-with-vscode.md) to integrate with VS Code via:
   - Continue extension for AI chat and code assistance
   - LM Studio SDK for programmatic access

## Features

✅ **100% Local** - All processing happens on your machine  
✅ **Private** - No data sent to cloud services  
✅ **Free** - No API costs or subscriptions  
✅ **Flexible** - Use with Continue extension or programmatically via SDK  

## Requirements

- LM Studio installed ([Download](https://lmstudio.ai))
- VS Code with Continue extension (for AI assistance)
- Node.js and npm (for SDK usage)